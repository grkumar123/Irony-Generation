{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ViT_Keras_Tensorflow.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples**"],"metadata":{"id":"H9_jf3XB3_zx"}},{"cell_type":"markdown","source":["**https://www.cs.toronto.edu/~kriz/cifar.html**"],"metadata":{"id":"koVd-vip6ODo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTBficDp33JT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653192248360,"user_tz":-330,"elapsed":4228,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"aae1e611-51a5-400b-cab9-cf6182781901"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n"]}],"source":["!pip install einops\n","  \n","import math\n","\n","import six\n","from einops.layers.tensorflow import Rearrange\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import TensorBoard\n","\n","from tensorflow.keras import datasets\n","\n","import logging\n","import numpy as np\n","\n","from fastprogress import master_bar, progress_bar"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"_R3l0qlu34u_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653192248361,"user_tz":-330,"elapsed":30,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"afb0d869-ac2b-48fe-d514-a9a62ee411ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun May 22 04:04:07 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   68C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["def gelu(x):\n","    \"\"\"Gaussian Error Linear Unit.\n","    This is a smoother version of the RELU.\n","    Original paper: https://arxiv.org/abs/1606.08415\n","    Args:\n","        x: float Tensor to perform activation.\n","    Returns:\n","        `x` with the GELU activation applied.\n","    \"\"\"\n","    cdf = 0.5 * (1.0 + tf.tanh(\n","        (math.sqrt(2 / math.pi) * (x + 0.044715 * tf.pow(x, 3)))))\n","    return x * cdf\n","\n","\n","def get_activation(identifier):\n","    \"\"\"Maps a identifier to a Python function, e.g., \"relu\" => `tf.nn.relu`.\n","    It checks string first and if it is one of customized activation not in TF,\n","    the corresponding activation will be returned. For non-customized activation\n","    names and callable identifiers, always fallback to tf.keras.activations.get.\n","    Args:\n","        identifier: String name of the activation function or callable.\n","    Returns:\n","        A Python function corresponding to the activation function.\n","    \"\"\"\n","    if isinstance(identifier, six.string_types):\n","        name_to_fn = {\"gelu\": gelu}\n","        identifier = str(identifier).lower()\n","        if identifier in name_to_fn:\n","            return tf.keras.activations.get(name_to_fn[identifier])\n","    return tf.keras.activations.get(identifier)\n","\n","\n","class Residual(tf.keras.Model):\n","\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def call(self, x):\n","        return self.fn(x) + x\n","\n","\n","class PreNorm(tf.keras.Model):\n","\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n","        self.fn = fn\n","\n","    def call(self, x):\n","        return self.fn(self.norm(x))\n","\n","\n","class FeedForward(tf.keras.Model):\n","\n","    def __init__(self, dim, hidden_dim):\n","        super().__init__()\n","        self.net = tf.keras.Sequential([tf.keras.layers.Dense(hidden_dim, activation=get_activation('gelu')),\n","                                        tf.keras.layers.Dense(dim)])\n","\n","    def call(self, x):\n","        return self.net(x)\n","\n","class Attention(tf.keras.Model):\n","\n","    def __init__(self, dim, heads = 8):\n","        super().__init__()\n","        self.heads = heads\n","        self.scale = dim ** -0.5\n","\n","        self.to_qkv = tf.keras.layers.Dense(dim * 3, use_bias=False)\n","        self.to_out = tf.keras.layers.Dense(dim)\n","\n","        self.rearrange_qkv = Rearrange('b n (qkv h d) -> qkv b h n d', qkv = 3, h = self.heads)\n","        self.rearrange_out = Rearrange('b h n d -> b n (h d)')\n","\n","    def call(self, x):\n","        qkv = self.to_qkv(x)\n","        qkv = self.rearrange_qkv(qkv)\n","        q = qkv[0]\n","        k = qkv[1]\n","        v = qkv[2]\n","\n","        dots = tf.einsum('bhid,bhjd->bhij', q, k) * self.scale\n","        attn = tf.nn.softmax(dots,axis=-1)\n","\n","        out = tf.einsum('bhij,bhjd->bhid', attn, v)\n","        out = self.rearrange_out(out)\n","        out =  self.to_out(out)\n","        return out\n","\n","class Transformer(tf.keras.Model):\n","\n","    def __init__(self, dim, depth, heads, mlp_dim):\n","        super().__init__()\n","        layers = []\n","        for _ in range(depth):\n","            layers.extend([\n","                Residual(PreNorm(dim, Attention(dim, heads = heads))),\n","                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n","            ])\n","        self.net = tf.keras.Sequential(layers)\n","\n","    def call(self, x):\n","        return self.net(x)\n","\n","class ViT(tf.keras.Model):\n","\n","    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels=3):\n","        super().__init__()\n","        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n","        num_patches = (image_size // patch_size) ** 2\n","        patch_dim = channels * patch_size ** 2\n","\n","        self.patch_size = patch_size\n","        self.dim = dim\n","        self.pos_embedding = self.add_weight(\"position_embeddings\",\n","                                             shape=[num_patches + 1,\n","                                                    dim],\n","                                             initializer=tf.keras.initializers.RandomNormal(),\n","                                             dtype=tf.float32)\n","        self.patch_to_embedding = tf.keras.layers.Dense(dim)\n","        self.cls_token = self.add_weight(\"cls_token\",\n","                                         shape=[1,\n","                                                1,\n","                                                dim],\n","                                         initializer=tf.keras.initializers.RandomNormal(),\n","                                         dtype=tf.float32)\n","\n","        self.rearrange = Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=self.patch_size, p2=self.patch_size)\n","\n","        self.transformer = Transformer(dim, depth, heads, mlp_dim)\n","\n","        self.to_cls_token = tf.identity\n","\n","        self.mlp_head = tf.keras.Sequential([tf.keras.layers.Dense(mlp_dim, activation=get_activation('gelu')),\n","                                        tf.keras.layers.Dense(num_classes)])\n","\n","    @tf.function\n","    def call(self, img):\n","        shapes = tf.shape(img)\n","\n","        x = self.rearrange(img)\n","        x = self.patch_to_embedding(x)\n","\n","        cls_tokens = tf.broadcast_to(self.cls_token,(shapes[0],1,self.dim))\n","        x = tf.concat((cls_tokens, x), axis=1)\n","        x += self.pos_embedding\n","        x = self.transformer(x)\n","\n","        x = self.to_cls_token(x[:, 0])\n","        return self.mlp_head(x)"],"metadata":{"id":"115rc44Q3421"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger = logging.getLogger(__name__)\n","\n","\n","class TrainerConfig:\n","    # optimization parameters\n","    max_epochs = 10\n","    batch_size = 64\n","    learning_rate = 1e-3\n","    # checkpoint settings\n","    ckpt_path = None\n","\n","    def __init__(self, **kwargs):\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)"],"metadata":{"id":"uu0BH2ZI345d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Trainer:\n","\n","    def __init__(self, model, model_config, train_dataset, train_dataset_len, test_dataset, test_dataset_len, config):\n","        self.train_dataset = train_dataset.batch(config.batch_size)\n","        self.train_dataset_len = train_dataset_len\n","        self.test_dataset = test_dataset\n","        self.test_dataset_len = None\n","        self.test_dist_dataset = None\n","        if self.test_dataset:\n","            self.test_dataset = test_dataset.batch(config.batch_size)\n","            self.test_dataset_len = test_dataset_len\n","        self.config = config\n","        self.tokens = 0\n","        self.strategy = tf.distribute.OneDeviceStrategy(\"GPU:0\")\n","        if len(tf.config.list_physical_devices('GPU')) > 1:\n","            self.strategy = tf.distribute.MirroredStrategy()\n","\n","        with self.strategy.scope():\n","            self.model = model(**model_config)\n","            self.optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)\n","            self.cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n","            self.train_dist_dataset = self.strategy.experimental_distribute_dataset(self.train_dataset)\n","            if self.test_dataset:\n","                self.test_dist_dataset = self.strategy.experimental_distribute_dataset(self.test_dataset)\n","\n","    def save_checkpoints(self):\n","        if self.config.ckpt_path is not None:\n","            self.model.save_weights(self.config.ckpt_path)\n","\n","\n","    def train(self):\n","\n","        train_loss_metric = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n","        test_loss_metric = tf.keras.metrics.Mean('testing_loss', dtype=tf.float32)\n","\n","        train_accuracy = tf.keras.metrics.Accuracy('training_accuracy', dtype=tf.float32)\n","        test_accuracy = tf.keras.metrics.Accuracy('testing_accuracy', dtype=tf.float32)\n","\n","        @tf.function\n","        def train_step(dist_inputs):\n","\n","            def step_fn(inputs):\n","\n","                X, Y = inputs\n","\n","                with tf.GradientTape() as tape:\n","                # training=True is only needed if there are layers with different\n","                # behavior during training versus inference (e.g. Dropout).\n","                    logits = self.model(X,training=True)\n","                    num_labels = tf.shape(logits)[-1]\n","                    label_mask = tf.math.logical_not(Y < 0)\n","                    label_mask = tf.reshape(label_mask,(-1,))\n","                    logits = tf.reshape(logits,(-1,num_labels))\n","                    logits_masked = tf.boolean_mask(logits,label_mask)\n","                    label_ids = tf.reshape(Y,(-1,))\n","                    label_ids_masked = tf.boolean_mask(label_ids,label_mask)\n","                    cross_entropy = self.cce(label_ids_masked, logits_masked)\n","                    loss = tf.reduce_sum(cross_entropy) * (1.0 / self.config.batch_size)\n","                    y_pred = tf.argmax(tf.nn.softmax(logits,axis=-1),axis=-1)\n","                    train_accuracy.update_state(tf.squeeze(Y),y_pred)\n","\n","                grads = tape.gradient(loss, self.model.trainable_variables)\n","                self.optimizer.apply_gradients(list(zip(grads, self.model.trainable_variables)))\n","                return cross_entropy\n","\n","            per_example_losses = self.strategy.run(step_fn, args=(dist_inputs,))\n","            sum_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_example_losses, axis=0)\n","            mean_loss = sum_loss / self.config.batch_size\n","            return mean_loss\n","\n","        @tf.function\n","        def test_step(dist_inputs):\n","\n","            def step_fn(inputs):\n","\n","                X, Y = inputs\n","                # training=True is only needed if there are layers with different\n","                # behavior during training versus inference (e.g. Dropout).\n","                logits = self.model(X,training=False)\n","                num_labels = tf.shape(logits)[-1]\n","                label_mask = tf.math.logical_not(Y < 0)\n","                label_mask = tf.reshape(label_mask,(-1,))\n","                logits = tf.reshape(logits,(-1,num_labels))\n","                logits_masked = tf.boolean_mask(logits,label_mask)\n","                label_ids = tf.reshape(Y,(-1,))\n","                label_ids_masked = tf.boolean_mask(label_ids,label_mask)\n","                cross_entropy = self.cce(label_ids_masked, logits_masked)\n","                loss = tf.reduce_sum(cross_entropy) * (1.0 / self.config.batch_size)\n","                y_pred = tf.argmax(tf.nn.softmax(logits,axis=-1),axis=-1)\n","                test_accuracy.update_state(tf.squeeze(Y),y_pred)\n","\n","                return cross_entropy\n","\n","            per_example_losses = self.strategy.run(step_fn, args=(dist_inputs,))\n","            sum_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_example_losses, axis=0)\n","            mean_loss = sum_loss / self.config.batch_size\n","            return mean_loss\n","\n","        train_pb_max_len = math.ceil(float(self.train_dataset_len)/float(self.config.batch_size))\n","        test_pb_max_len = math.ceil(float(self.test_dataset_len)/float(self.config.batch_size)) if self.test_dataset else None\n","\n","        epoch_bar = master_bar(range(self.config.max_epochs))\n","        with self.strategy.scope():\n","            for epoch in epoch_bar:\n","                for inputs in progress_bar(self.train_dist_dataset,total=train_pb_max_len,parent=epoch_bar):\n","                    loss = train_step(inputs)\n","                    self.tokens += tf.reduce_sum(tf.cast(inputs[1]>=0,tf.int32)).numpy()\n","                    train_loss_metric(loss)\n","                    epoch_bar.child.comment = f'training loss : {train_loss_metric.result()}'\n","                print(f\"epoch {epoch+1}: train loss {train_loss_metric.result():.5f}. train accuracy {train_accuracy.result():.5f}\")\n","                train_loss_metric.reset_states()\n","                train_accuracy.reset_states()\n","\n","                if self.test_dist_dataset:\n","                    for inputs in progress_bar(self.test_dist_dataset,total=test_pb_max_len,parent=epoch_bar):\n","                        loss = test_step(inputs)\n","                        test_loss_metric(loss)\n","                        epoch_bar.child.comment = f'testing loss : {test_loss_metric.result()}'\n","                    print(f\"epoch {epoch+1}: test loss {test_loss_metric.result():.5f}. test accuracy {test_accuracy.result():.5f}\")\n","                    test_loss_metric.reset_states()\n","                    test_accuracy.reset_states()\n","\n","                self.save_checkpoints()"],"metadata":{"id":"MdMVp4_f348M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"],"metadata":{"id":"x3Iavkcv34-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images"],"metadata":{"id":"4lME8X1G63JF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_labels"],"metadata":{"id":"Fnz5LRxi6vqR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_images"],"metadata":{"id":"FI9uuMoo7w4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_labels"],"metadata":{"id":"SR70Nlhf7w7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images = tf.cast(train_images.reshape((-1, 3, 32, 32)),dtype=tf.float32)\n","test_images = tf.cast(test_images.reshape((-1, 3, 32, 32)),dtype=tf.float32)\n","train_images, test_images = train_images / 255.0, test_images / 255.0"],"metadata":{"id":"wDpdLeE535Bf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NyKxj1bf6qMa","executionInfo":{"status":"ok","timestamp":1653192250653,"user_tz":-330,"elapsed":68,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"ec9a3ce0-bd22-4371-a9b8-9bcc9543cbd1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(50000, 3, 32, 32), dtype=float32, numpy=\n","array([[[[0.23137255, 0.24313726, 0.24705882, ..., 0.3647059 ,\n","          0.5137255 , 0.40392157],\n","         [0.3019608 , 0.49019608, 0.3882353 , ..., 0.4392157 ,\n","          0.29411766, 0.52156866],\n","         [0.4117647 , 0.27058825, 0.53333336, ..., 0.5803922 ,\n","          0.4862745 , 0.40392157],\n","         ...,\n","         [0.21176471, 0.12941177, 0.3372549 , ..., 0.52156866,\n","          0.36078432, 0.21568628],\n","         [0.6039216 , 0.47843137, 0.36862746, ..., 0.26666668,\n","          0.3137255 , 0.15686275],\n","         [0.05098039, 0.38039216, 0.20784314, ..., 0.36078432,\n","          0.29803923, 0.6862745 ]],\n","\n","        [[0.5058824 , 0.41568628, 0.5568628 , ..., 0.5254902 ,\n","          0.3647059 , 0.22352941],\n","         [0.5686275 , 0.44705883, 0.34901962, ..., 0.21568628,\n","          0.43529412, 0.23529412],\n","         [0.05490196, 0.57254905, 0.3372549 , ..., 0.5882353 ,\n","          0.44313726, 0.81960785],\n","         ...,\n","         [0.36078432, 0.6       , 0.40784314, ..., 0.44313726,\n","          0.2627451 , 0.6784314 ],\n","         [0.5882353 , 0.4392157 , 0.7921569 , ..., 0.53333336,\n","          0.46666667, 0.19607843],\n","         [0.56078434, 0.40784314, 0.2509804 , ..., 0.5176471 ,\n","          0.67058825, 0.5254902 ]],\n","\n","        [[0.3882353 , 0.64705884, 0.4509804 , ..., 0.39607844,\n","          0.21568628, 0.53333336],\n","         [0.39607844, 0.23529412, 0.5803922 , ..., 0.7019608 ,\n","          0.63529414, 0.3254902 ],\n","         [0.5529412 , 0.4       , 0.25490198, ..., 0.41960785,\n","          0.7411765 , 0.5921569 ],\n","         ...,\n","         [0.69411767, 0.5647059 , 0.45490196, ..., 0.32156864,\n","          0.6509804 , 0.5176471 ],\n","         [0.3372549 , 0.6392157 , 0.5019608 , ..., 0.4117647 ,\n","          0.27058825, 0.5647059 ],\n","         [0.37254903, 0.21568628, 0.4392157 , ..., 0.48235294,\n","          0.36078432, 0.28235295]]],\n","\n","\n","       [[[0.6039216 , 0.69411767, 0.73333335, ..., 0.43137255,\n","          0.41568628, 0.41960785],\n","         [0.38431373, 0.42745098, 0.40784314, ..., 0.45882353,\n","          0.40392157, 0.4       ],\n","         [0.39607844, 0.3254902 , 0.37254903, ..., 0.30980393,\n","          0.31764707, 0.27450982],\n","         ...,\n","         [0.25882354, 0.18039216, 0.5803922 , ..., 0.21960784,\n","          0.23137255, 0.16078432],\n","         [0.19215687, 0.18039216, 0.19215687, ..., 0.60784316,\n","          0.49019608, 0.5921569 ],\n","         [0.70980394, 0.5019608 , 0.627451  , ..., 0.7647059 ,\n","          0.77254903, 0.5529412 ]],\n","\n","        [[0.36078432, 0.29411766, 0.6117647 , ..., 0.30980393,\n","          0.32156864, 0.24705882],\n","         [0.23137255, 0.22745098, 0.2627451 , ..., 0.60784316,\n","          0.45882353, 0.57254905],\n","         [0.67058825, 0.49019608, 0.627451  , ..., 0.7764706 ,\n","          0.7882353 , 0.57254905],\n","         ...,\n","         [0.3882353 , 0.60784316, 0.57254905, ..., 0.7921569 ,\n","          0.76862746, 0.7764706 ],\n","         [0.64705884, 0.5294118 , 0.8039216 , ..., 0.8       ,\n","          0.7411765 , 0.5764706 ],\n","         [0.60784316, 0.627451  , 0.7058824 , ..., 0.61960787,\n","          0.5137255 , 0.54509807]],\n","\n","        [[0.54509807, 0.90588236, 0.85882354, ..., 0.68235296,\n","          0.69411767, 0.61960787],\n","         [0.47843137, 0.38431373, 0.627451  , ..., 0.8235294 ,\n","          0.7607843 , 0.5686275 ],\n","         [0.63529414, 0.6509804 , 0.7137255 , ..., 0.5294118 ,\n","          0.40392157, 0.42745098],\n","         ...,\n","         [0.6392157 , 0.5803922 , 0.47058824, ..., 0.41960785,\n","          0.43137255, 0.39607844],\n","         [0.3882353 , 0.3882353 , 0.3647059 , ..., 0.02352941,\n","          0.04313726, 0.03921569],\n","         [0.03529412, 0.04705882, 0.09803922, ..., 0.56078434,\n","          0.52156866, 0.5647059 ]]],\n","\n","\n","       [[[1.        , 1.        , 1.        , ..., 0.99215686,\n","          0.99215686, 0.99215686],\n","         [0.99215686, 0.99215686, 0.99215686, ..., 0.9647059 ,\n","          0.9529412 , 0.99215686],\n","         [0.9882353 , 0.98039216, 0.9882353 , ..., 0.99215686,\n","          0.99215686, 0.99215686],\n","         ...,\n","         [0.27450982, 0.2627451 , 0.5019608 , ..., 0.87058824,\n","          0.9098039 , 0.87058824],\n","         [1.        , 1.        , 1.        , ..., 0.4745098 ,\n","          0.70980394, 0.7254902 ],\n","         [0.7019608 , 0.9647059 , 0.972549  , ..., 0.13333334,\n","          0.15294118, 0.2       ]],\n","\n","        [[0.16862746, 0.16862746, 0.42352942, ..., 0.6313726 ,\n","          0.70980394, 0.6       ],\n","         [1.        , 1.        , 1.        , ..., 0.28627452,\n","          0.45490196, 0.4745098 ],\n","         [0.4509804 , 0.8784314 , 0.9019608 , ..., 0.12156863,\n","          0.12156863, 0.12941177],\n","         ...,\n","         [0.20784314, 0.21176471, 0.17254902, ..., 0.16078432,\n","          0.1764706 , 0.09019608],\n","         [0.08235294, 0.10588235, 0.09803922, ..., 0.2901961 ,\n","          0.34117648, 0.3137255 ],\n","         [0.4392157 , 0.5176471 , 0.40784314, ..., 0.2       ,\n","          0.17254902, 0.16470589]],\n","\n","        [[0.20392157, 0.15686275, 0.1254902 , ..., 0.1764706 ,\n","          0.19607843, 0.11372549],\n","         [0.1254902 , 0.14901961, 0.10980392, ..., 0.28235295,\n","          0.3254902 , 0.31764707],\n","         [0.4392157 , 0.48235294, 0.42745098, ..., 0.19215687,\n","          0.14117648, 0.14901961],\n","         ...,\n","         [0.41568628, 0.44313726, 0.4117647 , ..., 0.36078432,\n","          0.30588236, 0.3647059 ],\n","         [0.34509805, 0.30980393, 0.36862746, ..., 0.3372549 ,\n","          0.3372549 , 0.2509804 ],\n","         [0.30588236, 0.30588236, 0.2509804 , ..., 0.3137255 ,\n","          0.3372549 , 0.32941177]]],\n","\n","\n","       ...,\n","\n","\n","       [[[0.13725491, 0.69803923, 0.92156863, ..., 0.94509804,\n","          0.22745098, 0.7137255 ],\n","         [0.9490196 , 0.23137255, 0.7137255 , ..., 0.85882354,\n","          0.9607843 , 0.80784315],\n","         [0.9254902 , 0.9764706 , 0.8862745 , ..., 0.34901962,\n","          0.5803922 , 0.7411765 ],\n","         ...,\n","         [0.21960784, 0.30980393, 0.44313726, ..., 0.03137255,\n","          0.08627451, 0.06666667],\n","         [0.6509804 , 0.7882353 , 0.89411765, ..., 0.6431373 ,\n","          0.5176471 , 0.6       ],\n","         [0.6862745 , 0.27058825, 0.36078432, ..., 0.28235295,\n","          0.38039216, 0.18431373]],\n","\n","        [[0.2784314 , 0.38039216, 0.59607846, ..., 0.03921569,\n","          0.07843138, 0.0627451 ],\n","         [0.8352941 , 0.95686275, 1.        , ..., 0.64705884,\n","          0.58431375, 0.6392157 ],\n","         [0.6745098 , 0.27450982, 0.3764706 , ..., 0.2901961 ,\n","          0.4       , 0.19607843],\n","         ...,\n","         [0.19607843, 0.16862746, 0.26666668, ..., 0.28627452,\n","          0.34117648, 0.34509805],\n","         [0.43137255, 0.44313726, 0.28627452, ..., 0.09411765,\n","          0.16078432, 0.08627451],\n","         [0.07450981, 0.13333334, 0.05882353, ..., 0.12156863,\n","          0.12156863, 0.15686275]],\n","\n","        [[0.21568628, 0.17254902, 0.23921569, ..., 0.20784314,\n","          0.27450982, 0.1882353 ],\n","         [0.2627451 , 0.3137255 , 0.20392157, ..., 0.10588235,\n","          0.14901961, 0.07843138],\n","         [0.05490196, 0.12156863, 0.05490196, ..., 0.14901961,\n","          0.09019608, 0.13333334],\n","         ...,\n","         [0.17254902, 0.21960784, 0.28627452, ..., 0.28235295,\n","          0.15294118, 0.22745098],\n","         [0.29411766, 0.13333334, 0.20784314, ..., 0.3019608 ,\n","          0.4       , 0.20392157],\n","         [0.28627452, 0.3764706 , 0.18039216, ..., 0.04705882,\n","          0.12156863, 0.19607843]]],\n","\n","\n","       [[[0.7411765 , 0.827451  , 0.9411765 , ..., 0.91764706,\n","          0.7019608 , 0.7921569 ],\n","         [0.9137255 , 0.7058824 , 0.7921569 , ..., 0.8117647 ,\n","          0.90588236, 0.73333335],\n","         [0.80784315, 0.9019608 , 0.73333335, ..., 0.6627451 ,\n","          0.7607843 , 0.8627451 ],\n","         ...,\n","         [0.68235296, 0.78431374, 0.6627451 , ..., 0.6156863 ,\n","          0.65882355, 0.7529412 ],\n","         [0.59607846, 0.69803923, 0.83137256, ..., 0.84313726,\n","          0.7019608 , 0.7490196 ],\n","         [0.8392157 , 0.6862745 , 0.7411765 , ..., 0.67058825,\n","          0.7607843 , 0.5803922 ]],\n","\n","        [[0.6392157 , 0.7411765 , 0.5686275 , ..., 0.47058824,\n","          0.5372549 , 0.6431373 ],\n","         [0.6431373 , 0.70980394, 0.8117647 , ..., 0.8235294 ,\n","          0.7372549 , 0.7490196 ],\n","         [0.8156863 , 0.7176471 , 0.7294118 , ..., 0.61960787,\n","          0.6784314 , 0.5882353 ],\n","         ...,\n","         [0.9490196 , 0.90588236, 0.8901961 , ..., 0.7529412 ,\n","          0.8352941 , 0.6039216 ],\n","         [0.65882355, 0.7137255 , 0.5529412 , ..., 0.6509804 ,\n","          0.6117647 , 0.48235294],\n","         [0.54901963, 0.49019608, 0.30588236, ..., 0.90588236,\n","          0.9098039 , 0.90588236]],\n","\n","        [[0.93333334, 0.8509804 , 0.84313726, ..., 0.58431375,\n","          0.62352943, 0.6117647 ],\n","         [0.6627451 , 0.69803923, 0.61960787, ..., 0.67058825,\n","          0.63529414, 0.5176471 ],\n","         [0.58431375, 0.5176471 , 0.30980393, ..., 0.4745098 ,\n","          0.8117647 , 0.80784315],\n","         ...,\n","         [0.7764706 , 0.7411765 , 0.6784314 , ..., 0.24705882,\n","          0.2627451 , 0.23529412],\n","         [0.22352941, 0.24705882, 0.21960784, ..., 0.5529412 ,\n","          0.50980395, 0.6431373 ],\n","         [0.63529414, 0.58431375, 0.6862745 , ..., 0.7647059 ,\n","          0.74509805, 0.67058825]]],\n","\n","\n","       [[[0.8980392 , 0.8980392 , 0.9372549 , ..., 0.95686275,\n","          0.9098039 , 0.9098039 ],\n","         [0.9490196 , 0.9098039 , 0.9098039 , ..., 0.8352941 ,\n","          0.89411765, 0.83137256],\n","         [0.84313726, 0.9019608 , 0.83137256, ..., 0.87058824,\n","          0.8745098 , 0.9137255 ],\n","         ...,\n","         [0.3019608 , 0.3019608 , 0.3019608 , ..., 0.4627451 ,\n","          0.34901962, 0.28235295],\n","         [0.31764707, 0.28235295, 0.27058825, ..., 0.23921569,\n","          0.64705884, 0.4862745 ],\n","         [0.4745098 , 0.627451  , 0.48235294, ..., 0.18039216,\n","          0.18039216, 0.39215687]],\n","\n","        [[0.21176471, 0.22745098, 0.40392157, ..., 0.45882353,\n","          0.36078432, 0.2901961 ],\n","         [0.36862746, 0.3529412 , 0.32941177, ..., 0.15686275,\n","          0.6745098 , 0.36078432],\n","         [0.35686275, 0.61960787, 0.3529412 , ..., 0.10980392,\n","          0.10588235, 0.39215687],\n","         ...,\n","         [0.39607844, 0.3137255 , 0.32941177, ..., 0.37254903,\n","          0.3882353 , 0.48235294],\n","         [0.50980395, 0.5176471 , 0.49411765, ..., 0.08627451,\n","          0.08235294, 0.03921569],\n","         [0.48235294, 0.47058824, 0.44705883, ..., 0.37254903,\n","          0.16862746, 0.18431373]],\n","\n","        [[0.20392157, 0.15686275, 0.18431373, ..., 0.38431373,\n","          0.39215687, 0.4627451 ],\n","         [0.4862745 , 0.49019608, 0.48235294, ..., 0.07843138,\n","          0.07450981, 0.05490196],\n","         [0.4862745 , 0.4745098 , 0.45490196, ..., 0.36862746,\n","          0.34117648, 0.34901962],\n","         ...,\n","         [0.47843137, 0.46666667, 0.44705883, ..., 0.30980393,\n","          0.34117648, 0.3254902 ],\n","         [0.29411766, 0.27450982, 0.2627451 , ..., 0.5294118 ,\n","          0.49019608, 0.57254905],\n","         [0.5529412 , 0.5137255 , 0.5921569 , ..., 0.6392157 ,\n","          0.6392157 , 0.6313726 ]]]], dtype=float32)>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["test_images"],"metadata":{"id":"hboB8B9P6qPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = tf.data.Dataset.from_tensor_slices(train_images,)\n","train_y = tf.data.Dataset.from_tensor_slices(train_labels)\n","train_dataset = tf.data.Dataset.zip((train_x,train_y))\n","test_x = tf.data.Dataset.from_tensor_slices(test_images)\n","test_y = tf.data.Dataset.from_tensor_slices(test_labels)\n","test_dataset = tf.data.Dataset.zip((test_x,test_y))"],"metadata":{"id":"h5VpVuq435EO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KsUxjhZ7VIe","executionInfo":{"status":"ok","timestamp":1653192250655,"user_tz":-330,"elapsed":50,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"36917566-a107-4124-a09b-e009a9afc2cd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TensorSliceDataset element_spec=TensorSpec(shape=(3, 32, 32), dtype=tf.float32, name=None)>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["train_y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RtERD4z7VLS","executionInfo":{"status":"ok","timestamp":1653192250655,"user_tz":-330,"elapsed":39,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"1ebf86fc-5c8d-4c75-bc2a-57aafae87186"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TensorSliceDataset element_spec=TensorSpec(shape=(1,), dtype=tf.uint8, name=None)>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7JcSnzz7VN3","executionInfo":{"status":"ok","timestamp":1653192250656,"user_tz":-330,"elapsed":34,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"fb4c5df7-be5e-4af6-8edf-150f352f8eb3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<ZipDataset element_spec=(TensorSpec(shape=(3, 32, 32), dtype=tf.float32, name=None), TensorSpec(shape=(1,), dtype=tf.uint8, name=None))>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["test_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jO-fjSYz7VQ8","executionInfo":{"status":"ok","timestamp":1653192250657,"user_tz":-330,"elapsed":32,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"9b157e79-0cc5-4e76-ed3a-79e76440c789"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TensorSliceDataset element_spec=TensorSpec(shape=(3, 32, 32), dtype=tf.float32, name=None)>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["test_y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L768ru9h7dZI","executionInfo":{"status":"ok","timestamp":1653192250657,"user_tz":-330,"elapsed":29,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"eb04bdb1-d0e6-41ed-b2d9-9d51ba9b40d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TensorSliceDataset element_spec=TensorSpec(shape=(1,), dtype=tf.uint8, name=None)>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["test_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u9C-CqZi7dcJ","executionInfo":{"status":"ok","timestamp":1653192250658,"user_tz":-330,"elapsed":26,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"e4c0bdc4-7e02-4843-f1cb-7546da8bf0f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<ZipDataset element_spec=(TensorSpec(shape=(3, 32, 32), dtype=tf.float32, name=None), TensorSpec(shape=(1,), dtype=tf.uint8, name=None))>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["tconf = TrainerConfig(max_epochs=10, batch_size=64, learning_rate=1e-3)"],"metadata":{"id":"PsyV9NoM35G9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tconf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfvXlBun7kSN","executionInfo":{"status":"ok","timestamp":1653192250660,"user_tz":-330,"elapsed":24,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"e71fe7a0-f015-4333-97b1-1b70004acd19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.TrainerConfig at 0x7fbd60465590>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# sample model config.\n","model_config = {\"image_size\":32,\n","                \"patch_size\":4,\n","                \"num_classes\":10,\n","                \"dim\":64,\n","                \"depth\":3,\n","                \"heads\":4,\n","                \"mlp_dim\":128}"],"metadata":{"id":"pVh83kgv35J_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(ViT, model_config, train_dataset, len(train_images), test_dataset, len(test_images), tconf)"],"metadata":{"id":"LjYGRh_b35MZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"vN3ajDlC35P4","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"ok","timestamp":1653192374886,"user_tz":-330,"elapsed":122531,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"6bb5ea73-68fe-45c1-a593-557fefb2b985"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[""]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 1: train loss 1.80311. train accuracy 0.33608\n","epoch 1: test loss 1.56073. test accuracy 0.42910\n","epoch 2: train loss 1.52367. train accuracy 0.44404\n","epoch 2: test loss 1.44644. test accuracy 0.47470\n","epoch 3: train loss 1.42401. train accuracy 0.48512\n","epoch 3: test loss 1.39743. test accuracy 0.49540\n","epoch 4: train loss 1.36127. train accuracy 0.50716\n","epoch 4: test loss 1.38524. test accuracy 0.50290\n","epoch 5: train loss 1.31074. train accuracy 0.52622\n","epoch 5: test loss 1.37218. test accuracy 0.50920\n","epoch 6: train loss 1.26606. train accuracy 0.54286\n","epoch 6: test loss 1.36734. test accuracy 0.51330\n","epoch 7: train loss 1.22605. train accuracy 0.55960\n","epoch 7: test loss 1.37927. test accuracy 0.51160\n","epoch 8: train loss 1.18917. train accuracy 0.57212\n","epoch 8: test loss 1.38303. test accuracy 0.51310\n","epoch 9: train loss 1.15717. train accuracy 0.58456\n","epoch 9: test loss 1.38691. test accuracy 0.51650\n","epoch 10: train loss 1.13130. train accuracy 0.59266\n","epoch 10: test loss 1.39624. test accuracy 0.51220\n"]}]}]}